# ğŸš— MLOps Vehicle Insurance Prediction

An end-to-end MLOps pipeline for predicting vehicle insurance cross-sell opportunities. This project demonstrates industry-standard MLOps practices including MongoDB integration, AWS S3 model registry, CI/CD pipelines with GitHub Actions, and Docker-based deployment on AWS EC2.

---

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Project Architecture](#project-architecture)
- [Project Structure](#project-structure)
- [Technologies Used](#technologies-used)
- [Getting Started](#getting-started)
- [MongoDB Setup](#mongodb-setup)
- [AWS Configuration](#aws-configuration)
- [Pipeline Components](#pipeline-components)
- [CI/CD Deployment](#cicd-deployment)
- [Usage](#usage)
- [Contributing](#contributing)
- [License](#license)

---

## ğŸ¯ Overview

This project aims to predict whether a health insurance customer would be interested in purchasing vehicle insurance. The solution implements a complete MLOps workflow from data ingestion to model deployment and monitoring.

### Business Problem

An insurance company needs to build a model to predict whether policyholders from the past year will also be interested in vehicle insurance. This helps the company plan its communication strategy to reach out to customers and optimize its business model and revenue.

---

## ğŸ—ï¸ Project Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MongoDB Atlas  â”‚â”€â”€â”€â”€â–¶â”‚  Data Ingestion â”‚â”€â”€â”€â”€â–¶â”‚ Data Validation â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                         â”‚
                                                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Model Pusher   â”‚â—€â”€â”€â”€â”€â”‚ Model Evaluationâ”‚â—€â”€â”€â”€â”€â”‚  Model Trainer  â”‚
â”‚   (AWS S3)      â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                      â–²
         â”‚                                               â”‚
         â–¼                                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                             â”‚Data Transformationâ”‚
â”‚  Flask App      â”‚                             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚  (AWS EC2)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Project Structure

```
MLOPS-Project-Vehicle-insurance/
â”‚
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ aws.yaml                 # CI/CD pipeline configuration
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ model.yaml                   # Model configuration
â”‚   â””â”€â”€ schema.yaml                  # Dataset schema for validation
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ components/                  # Pipeline components
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ data_ingestion.py
â”‚   â”‚   â”œâ”€â”€ data_validation.py
â”‚   â”‚   â”œâ”€â”€ data_transformation.py
â”‚   â”‚   â”œâ”€â”€ model_trainer.py
â”‚   â”‚   â”œâ”€â”€ model_evaluation.py
â”‚   â”‚   â””â”€â”€ model_pusher.py
â”‚   â”‚
â”‚   â”œâ”€â”€ pipline/                     # Training and prediction pipelines
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ training_pipeline.py
â”‚   â”‚   â””â”€â”€ prediction_pipeline.py
â”‚   â”‚
â”‚   â”œâ”€â”€ configuration/               # Connection configurations
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ mongo_db_connection.py
â”‚   â”‚   â””â”€â”€ aws_connection.py
â”‚   â”‚
â”‚   â”œâ”€â”€ cloud_storage/               # AWS S3 operations
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ aws_storage.py
â”‚   â”‚
â”‚   â”œâ”€â”€ data_access/                 # Data access layer
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ proj1_data.py
â”‚   â”‚
â”‚   â”œâ”€â”€ entity/                      # Data classes and configurations
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ config_entity.py
â”‚   â”‚   â”œâ”€â”€ artifact_entity.py
â”‚   â”‚   â”œâ”€â”€ estimator.py
â”‚   â”‚   â””â”€â”€ s3_estimator.py
â”‚   â”‚
â”‚   â”œâ”€â”€ constants/                   # Project constants
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/                       # Utility functions
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ main_utils.py
â”‚   â”‚
â”‚   â”œâ”€â”€ logger/                      # Logging configuration
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â””â”€â”€ exception/                   # Custom exception handling
â”‚       â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ notebook/                        # Jupyter notebooks
â”‚   â”œâ”€â”€ mongoDB_demo.ipynb           # MongoDB data upload
â”‚   â””â”€â”€ EDA_Feature_Engineering.ipynb
â”‚
â”œâ”€â”€ static/                          # Static files (CSS, JS)
â”œâ”€â”€ templates/                       # HTML templates for Flask app
â”œâ”€â”€ artifacts/                       # Generated artifacts (in .gitignore)
â”‚
â”œâ”€â”€ app.py                           # Flask application
â”œâ”€â”€ demo.py                          # Pipeline testing script
â”œâ”€â”€ template.py                      # Project template generator
â”œâ”€â”€ requirements.txt                 # Python dependencies
â”œâ”€â”€ setup.py                         # Package setup file
â”œâ”€â”€ pyproject.toml                   # Project configuration
â”œâ”€â”€ Dockerfile                       # Docker configuration
â”œâ”€â”€ .dockerignore                    # Docker ignore file
â””â”€â”€ README.md
```

---

## ğŸ› ï¸ Technologies Used

| Category | Technologies |
|----------|-------------|
| **Programming Language** | Python 3.10 |
| **ML Framework** | Scikit-learn |
| **Data Processing** | Pandas, NumPy |
| **Database** | MongoDB Atlas |
| **Cloud Platform** | AWS (S3, EC2, ECR) |
| **Model Registry** | AWS S3 Bucket |
| **Web Framework** | Flask |
| **Containerization** | Docker |
| **CI/CD** | GitHub Actions |
| **Visualization** | Matplotlib, Seaborn |

---

## âš™ï¸ Getting Started

### Prerequisites

- Python 3.10
- Conda (recommended)
- Git
- MongoDB Atlas account
- AWS Account

### Step 1: Create Project Template

```bash
python template.py
```

### Step 2: Setup Virtual Environment

```bash
# Create conda environment
conda create -n vehicle python=3.10 -y

# Activate environment
conda activate vehicle

# Install dependencies
pip install -r requirements.txt

# Verify local packages are installed
pip list
```

### Step 3: Configure Environment Variables

**For Bash:**
```bash
export MONGODB_URL="mongodb+srv://<username>:<password>@cluster.mongodb.net/?retryWrites=true&w=majority"
export AWS_ACCESS_KEY_ID="your_access_key"
export AWS_SECRET_ACCESS_KEY="your_secret_key"
```

**For PowerShell:**
```powershell
$env:MONGODB_URL = "mongodb+srv://<username>:<password>@cluster.mongodb.net/?retryWrites=true&w=majority"
$env:AWS_ACCESS_KEY_ID = "your_access_key"
$env:AWS_SECRET_ACCESS_KEY = "your_secret_key"
```

---

## ğŸƒ MongoDB Setup

1. **Create MongoDB Atlas Account**
   - Sign up at [MongoDB Atlas](https://www.mongodb.com/atlas)
   - Create a new project

2. **Create Cluster**
   - Click "Create Cluster"
   - Select M0 (Free Tier)
   - Click "Create Deployment"

3. **Configure Database User**
   - Set username and password
   - Create DB user

4. **Configure Network Access**
   - Go to "Network Access"
   - Add IP Address: `0.0.0.0/0` (allows access from anywhere)

5. **Get Connection String**
   - Go to project â†’ "Get Connection String" â†’ "Drivers"
   - Select Driver: Python, Version: 3.6 or later
   - Copy connection string and replace `<password>`

6. **Upload Data to MongoDB**
   - Open `notebook/mongoDB_demo.ipynb`
   - Select kernel: Python (vehicle environment)
   - Run cells to push data to MongoDB

7. **Verify Data**
   - Go to MongoDB Atlas â†’ Database â†’ Browse Collections
   - View your data in key-value format

---

## â˜ï¸ AWS Configuration

### IAM User Setup

1. Login to AWS Console
2. Set region to `us-east-1`
3. Go to IAM â†’ Create new user
4. Attach policy: `AdministratorAccess`
5. Create Access Key (CLI) and download CSV

### S3 Bucket Setup

1. Go to S3 Service â†’ Create Bucket
2. **Region:** us-east-1
3. **Bucket Name:** `my-model-mlopsproj`
4. Uncheck "Block all public access"
5. Create Bucket

### Constants Configuration

Update `src/constants/__init__.py`:
```python
MODEL_EVALUATION_CHANGED_THRESHOLD_SCORE: float = 0.02
MODEL_BUCKET_NAME = "my-model-mlopsproj"
MODEL_PUSHER_S3_KEY = "model-registry"
```

---

## ğŸ“Š Pipeline Components

### 1. Data Ingestion
- Connects to MongoDB using connection URL
- Fetches data in key-value format
- Transforms data to DataFrame
- Splits into train and test sets
- Saves raw data as artifacts

### 2. Data Validation
- Schema validation using `config/schema.yaml`
- Data quality checks
- Data drift detection

### 3. Data Transformation
- Feature engineering
- Handling missing values
- Encoding categorical variables
- Feature scaling

### 4. Model Trainer
- Model training with selected algorithm
- Hyperparameter configuration
- Model artifact generation

### 5. Model Evaluation
- Performance metrics calculation
- Comparison with existing model in S3
- Threshold-based model acceptance (0.02 improvement)

### 6. Model Pusher
- Push accepted model to AWS S3
- Model versioning in S3 bucket

---

## ğŸš€ CI/CD Deployment

### Docker Setup

The project includes `Dockerfile` and `.dockerignore` for containerization.

### EC2 Instance Setup

1. **Launch EC2 Instance**
   - Name: `vehicledata-machine`
   - Image: Ubuntu Server 24.04 (Free tier)
   - Instance Type: T2 Medium
   - Create key pair: `proj1key`
   - Allow HTTP/HTTPS traffic
   - Storage: 30GB

2. **Install Docker on EC2**
   ```bash
   sudo apt-get update -y
   sudo apt-get upgrade
   curl -fsSL https://get.docker.com -o get-docker.sh
   sudo sh get-docker.sh
   sudo usermod -aG docker ubuntu
   newgrp docker
   ```

### ECR Repository Setup

1. Go to AWS ECR â†’ Create Repository
2. **Region:** us-east-1
3. **Repository Name:** `vehicleproj`
4. Copy and save the URI

### GitHub Self-Hosted Runner

1. Go to GitHub Repository â†’ Settings â†’ Actions â†’ Runners
2. Click "New self-hosted runner"
3. Select OS: Linux
4. Run "Download" commands on EC2
5. Run "Configure" command:
   ```bash
   ./config.sh  # Runner name: self-hosted
   ./run.sh     # Start the runner
   ```

### GitHub Secrets Configuration

Go to GitHub â†’ Settings â†’ Secrets and Variables â†’ Actions â†’ New Repository Secret

| Secret Name | Value |
|-------------|-------|
| `AWS_ACCESS_KEY_ID` | Your AWS Access Key |
| `AWS_SECRET_ACCESS_KEY` | Your AWS Secret Key |
| `AWS_DEFAULT_REGION` | us-east-1 |
| `ECR_REPO` | ECR Repository URI |

### Configure EC2 Security Group

1. Go to EC2 Instance â†’ Security â†’ Security Groups
2. Edit Inbound Rules â†’ Add Rule
3. **Type:** Custom TCP
4. **Port Range:** 5080
5. **Source:** 0.0.0.0/0
6. Save Rules

### Trigger Deployment

CI/CD pipeline triggers automatically on push to main branch.

---

## ğŸ–¥ï¸ Usage

### Run Training Pipeline

```bash
python demo.py
```

### Start Web Application

```bash
python app.py
```

### Access Application

- **Local:** `http://localhost:5080`
- **EC2:** `http://<ec2-public-ip>:5080`

### Endpoints

| Endpoint | Description |
|----------|-------------|
| `/` | Home page with prediction form |
| `/training` | Trigger model training |
| `/predict` | Make predictions |

---

## ğŸ“ˆ Features Used

| Feature | Description |
|---------|-------------|
| Gender | Gender of the customer |
| Age | Age of the customer |
| Driving_License | Whether customer has driving license |
| Region_Code | Unique code for customer's region |
| Previously_Insured | Already has vehicle insurance |
| Vehicle_Age | Age of the vehicle |
| Vehicle_Damage | Vehicle was damaged in past |
| Annual_Premium | Amount paid as premium |
| Policy_Sales_Channel | Channel for policy outreach |
| Vintage | Number of days customer associated |

---

## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit changes (`git commit -m 'Add AmazingFeature'`)
4. Push to branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ“§ Contact

**Author:** Anjit  
**Project Link:** [https://github.com/taanjit/MLOPS-Project-Vehicle-insurance](https://github.com/taanjit/MLOPS-Project-Vehicle-insurance)

---

<p align="center">
  Made with â¤ï¸ for MLOps Learning
</p>
